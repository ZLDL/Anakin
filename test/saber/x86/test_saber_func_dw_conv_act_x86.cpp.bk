#include "saber/core/context.h"
#include "saber/funcs/reshape.h"
#include "test_saber_func_dw_conv_act_x86.h"
#include "saber/core/tensor_op.h"
#include "saber/saber_types.h"
#include <vector>
#include "./saber/funcs/conv_act.h"
#include "./saber/funcs/fc.h"
#include "test/x86/x86_test_common.h"

using namespace anakin::saber;
typedef Tensor<X86, AK_FLOAT, NCHW> ioTensor;
typedef Tensor<X86, AK_FLOAT, NCHW_C16> ioTensor_C16;

template <typename Layout>
bool compare_tensors(Tensor<X86, AK_FLOAT, Layout> &output, ioTensor &output_ref){

    Shape shape = output_ref.shape();
    int n = shape[0], oc = shape[1], oh = shape[2], ow = shape[3];
    for (int i = 0; i < n; ++i){
        for (int j = 0; j < oc / 16; ++j){
            for (int u = 0; u < oh; ++u){
                for (int v = 0; v < ow; ++v){
                    for (int m = 0; m < 16; ++m){
                         int out_idx = i * oc * oh * ow + j * oh * ow * 16 + u * ow * 16 + v *16 + m;
                         int out_ref_idx = i * oc * oh * ow + (j * 16 + m) * oh * ow + u * ow + v;
                         float out = *(output.mutable_data() + out_idx);
                         float out_ref = *(output_ref.mutable_data() + out_ref_idx);
                         float diff = out - out_ref;
                         float e = (std::abs(out_ref) > (float)1e-4) ? diff / out_ref : diff;
                         if ((std::abs(e) > 1e-4)){              
                            std::cout<<"out = " << out << std::endl;
                            std::cout<<"out_ref = " << out_ref << std::endl;
                            return false;        
                         }
                    }
                }
            }
        }
    }

    return true;
}

/* transfer input (NCHW) to  output NCHW_C16*/
void weight_reorder(Tensor<X86, AK_FLOAT, NCHW> &input, Tensor<X86, AK_FLOAT, NCHW_C16> &output){

    Shape shape = output.shape();
    for (int oc = 0; oc < shape[0]; ++oc){
        for (int ic_idx = 0; ic_idx < shape[1]; ++ic_idx){
            for (int kh = 0; kh < shape[2]; ++kh){
                for (int kw = 0; kw < shape[3]; ++kw){
                    for (int ic = 0; ic < shape[4]; ++ic){
                       int input_idx = oc * shape[1] * shape[2] * shape[3] * shape[4] +
                                       (ic_idx * shape[4] + ic) * shape[2] * shape[3] +
                                       kh * shape[3] + kw;
                       int output_idx = oc * shape[1] * shape[2] * shape[3] * shape[4] +
                                       ic_idx * shape[2] * shape[3] * shape[4] +
                                       kh * shape[3] * shape[4] +
                                       kw * shape[4] + ic;
                       *(output.mutable_data() + output_idx) = *(input.data() + input_idx);
                    }
                }
            }
        }
    } 

}

template<DataType Dtype, typename LayoutType>
void compute_ref_conv_relu_fwd(
        const std::vector<Tensor<X86, Dtype, LayoutType> *> inputs,
        std::vector<Tensor<X86, Dtype, LayoutType> *> outputs,
        ConvParam<Tensor<X86, Dtype, LayoutType>> *conv_param,
        ActivationParam<Tensor<X86, Dtype, LayoutType>> *act_param){

   typedef typename Tensor<X86, Dtype, LayoutType>::Dtype dtype;  
    
    auto src_data = reinterpret_cast<const dtype*>(inputs[0]->get_buf()-> get_data());
    auto dst_data_ref = reinterpret_cast<dtype*>(outputs[0]->mutable_data());
    auto weights_data = reinterpret_cast<const dtype*>(conv_param->weight()->get_buf()->get_data());
    bool with_bias = conv_param->bias() ? true : false;
    auto bias_data = reinterpret_cast<const dtype*>(conv_param -> bias() -> data());
    Shape shape = conv_param->bias()->shape();
    int mb_ = outputs[0] -> num();
    int oc_ = outputs[0] -> channel();
    int oh_ = outputs[0] -> height();
    int ow_ = outputs[0] -> width();

    int ic_ = inputs[0] -> channel();
    int ih_ = inputs[0] -> height();
    int iw_ = inputs[0] -> width();

    int gb_ = conv_param -> group;
    int kh_ = conv_param -> weight() -> height();
    int kw_ = conv_param -> weight() -> width();
    int strh_ = conv_param -> stride_h;
    int strw_ = conv_param -> stride_w;
    int padh_ = conv_param -> pad_h;
    int padw_ = conv_param -> pad_w;
    int dilw_ = conv_param -> dilation_h;
    int dilh_ = conv_param -> dilation_w;
    int oc_gb_ = oc_/gb_;
    int ic_gb_ = ic_/gb_;

    dtype negative_slope = act_param -> negative_slope;
    
#pragma omp parallel for collapse(5) schedule(static)
    for (int n = 0; n < mb_; ++n) {
        for (int g = 0; g < gb_; ++g) {
            for (int oc = 0; oc < oc_gb_ ; ++oc) {
                for (int oh = 0; oh < oh_; ++oh) {
                    for (int ow = 0; ow < ow_; ++ow) {
                        int oidx = n * gb_ * oc_gb_ * oh_ * ow_ + g * oc_gb_ * oh_ * ow_
                            + oc * oh_ * ow_ + oh * ow_ + ow;

                        dst_data_ref[oidx] = with_bias ? static_cast<dtype>(bias_data[g * oc_gb_ + oc]) : static_cast<dtype>(0);

                        for (int ic = 0; ic < ic_gb_; ++ic){
                            for (int kh = 0; kh < kh_; ++kh) {
                                for (int kw = 0; kw < kw_; ++kw) {
                                    int iw = ow * strw_ - padw_ + kw * (1 + dilw_);
                                    int ih = oh * strh_ - padh_ + kh * (1 + dilh_);
                                    if (iw < 0 || iw >= iw_) continue;
                                    if (ih < 0 || ih >= ih_) continue;

                                    int iidx = n * ic_ * ih_ * iw_ 
                                        + g * ic_gb_ * ih_ * iw_ 
                                        + ic * ih_ * iw_
                                        + ih * iw_ 
                                        + iw;
                                    int widx = g * oc_gb_ * ic_gb_ * kh_ * kw_
                                        + oc * ic_gb_ * kh_ * kw_
                                        + ic * kh_ * kw_
                                        + kh * kw_ 
                                        + kw;

                                    dst_data_ref[oidx] 
                                        += src_data[iidx] 
                                        * weights_data[widx];
                                }
                            }
                        }

                        if (dst_data_ref[oidx] < 0){
                            dst_data_ref[oidx] = static_cast<dtype>(
                                    negative_slope * dst_data_ref[oidx]);
                        }
                    }
                }
            }
        }
    }
}

struct conv_act_params {
   int n, g;
   int ic, ih, iw;
   int oc, oh, ow;
   int kh, kw;
   int pad_h, pad_w;
   int stride_h, stride_w;
   int dil_h, dil_w;
   float alpha, beta;
   float negative_slope;
   float coef;
};

 
template <typename dtype>
bool conv_act_test(conv_act_params &p) {

    // start Reshape & doInfer
    Context<X86> ctx_host;
    
    // create reference Tensor and Param
    Shape shape_input_ref(p.n, p.ic, p.ih, p.iw);
    ioTensor input_ref(shape_input_ref);
    fill_tensor_host_rand(input_ref);
    std::vector<ioTensor *> inputs_ref(1, &input_ref);
    
    Shape shape_output_ref(p.n, p.oc, p.oh, p.ow);
    ioTensor output_ref(shape_output_ref);  
    fill_tensor_host_const(output_ref, 0);
    std::vector<ioTensor *> outputs_ref(1, &output_ref);
    
    Shape shape_weight_ref(p.g, 1, p.kh, p.kw);
    ioTensor weight_ref(shape_weight_ref);
    fill_tensor_host_rand(weight_ref);

    Shape shape_bias_ref(1, 1, 1, p.oc);
    ioTensor bias_ref(shape_bias_ref);
    
    ConvParam<ioTensor> conv_param_ref(p.g, 
            p.pad_h, p.pad_w, 
            p.stride_h, p.stride_w, 
            p.dil_w, p.dil_h,
            &weight_ref, &bias_ref, p.alpha, p.beta);
    ActivationParam<ioTensor> act_param_ref(Active_relu);
    
    // compute reference
    compute_ref_conv_relu_fwd<AK_FLOAT, NCHW>(inputs_ref, outputs_ref, &conv_param_ref, &act_param_ref);
   
    // create VENDER Tensor and Param 
    Shape shape_input(p.n, p.ic/16, p.ih, p.iw, 16);
    ioTensor_C16 input(shape_input);
    std::vector<ioTensor_C16 *> inputs(1, &input);
    reorder<Tensor<X86, AK_FLOAT, NCHW>, Tensor<X86, AK_FLOAT, NCHW_C16>>(*inputs_ref[0], *inputs[0]);

    Shape shape_output(p.n, p.oc/16, p.oh, p.ow, 16);
    ioTensor_C16 output(shape_output);  
    fill_tensor_host_const(output, 0);
    std::vector<ioTensor_C16 *> outputs(1, &output);
    
   ConvParam<ioTensor> conv_param(p.g, 
            p.pad_h, p.pad_w, 
            p.stride_h, p.stride_w, 
            p.dil_w, p.dil_h,
            &weight_ref, &biasi_ref, p.alpha, p.beta);

    ActivationParam<ioTensor> act_param(Active_relu);
    ConvActiveParam<ioTensor> conv_act_param(conv_param, act_param);
    
    // compute VENDER conv_act 
    Conv_act<X86, AK_FLOAT, AK_FLOAT, AK_FLOAT, NCHW, NCHW_C16, NCHW_C16> conv_act_op;
    SaberStatus status = conv_act_op.init(inputs, outputs, conv_act_param, SPECIFY, SABER_IMPL, ctx_host);
    if (status == SaberSuccess) {
       conv_act_op(inputs, outputs, conv_act_param, ctx_host); 
       return compare_tensors<NCHW_C16>(*(outputs[0]), *(outputs_ref[0]));
    } else {
      std::cout<<"/*----------Init Failed!----------*/"<<std::endl;
      return false;
    }
}

using conv_act_params_float = conv_act_params;


TEST(TestSaberFuncConvActX86, test_func_conv_act) {
    Env<X86>::env_init();
   
    conv_act_params_float test_param[] = {
        conv_act_params_float{2, 16, 16, 3, 3, 16, 3, 3, 3, 3, 1, 1, 1, 1, 0, 0,
            float(1), float(0), float(0), float(1) }
    };

    for (int i = 0; i < ARRAY_SIZE(test_param); ++i)
    {
        bool flag = conv_act_test<float>(test_param[i]);
        if (flag)
            LOG(INFO) << "Passed Tested\n";
        else
            LOG(ERROR) << "Passed Failed\n";
    } 
}

int main(int argc, const char** argv){
    //initial logger;
    logger::init(argv[0]);
    InitTest();
    RUN_ALL_TESTS(argv[0]);
    return 0;
}

